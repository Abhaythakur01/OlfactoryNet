# Default training configuration

# Optimization
learning_rate: 0.001
weight_decay: 0.0001
batch_size: 32
max_epochs: 100

# Learning rate scheduler (ReduceLROnPlateau)
lr_patience: 10
lr_factor: 0.5
min_lr: 0.000001

# Early stopping
early_stopping_patience: 20
early_stopping_min_delta: 0.001

# Loss function
loss_type: bce  # "bce" or "focal"
use_class_weights: false  # Use inverse frequency weights for imbalanced labels
focal_gamma: 2.0  # Focal loss focusing parameter (only used if loss_type=focal)
focal_alpha: null  # Focal loss alpha (null for no alpha weighting)

# Gradient clipping
gradient_clip_val: 1.0

# Checkpointing
checkpoint_dir: checkpoints
save_best_only: true

# Validation
val_check_interval: 1  # Validate every N epochs

# Logging
use_wandb: false
wandb_project: olfactorynet
wandb_run_name: null  # null for auto-generated name
